{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3e035b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loaded RAG index with 18628 documents\n",
      "C:\\Users\\Gebruiker\\AppData\\Local\\Temp\\ipykernel_13412\\2948044167.py:918: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(elem_id=\"chat-window\", show_label=False, visible=False)\n",
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7882/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD http://127.0.0.1:7882/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/v3/tunnel-request \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on public URL: https://70099d6b58f6759acb.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: HEAD https://70099d6b58f6759acb.gradio.live \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://70099d6b58f6759acb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gebruiker\\AppData\\Roaming\\Python\\Python313\\site-packages\\gradio\\blocks.py:2010: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  state[block._id] = block.__class__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from anthropic import Anthropic\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from functools import lru_cache\n",
    "import faiss\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "import mimetypes\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import xml.etree.ElementTree as ET\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "# Path to logo and audio files\n",
    "logo_path = \"gnosis_logo.jpg\"\n",
    "audio_path = \"03 Fantasia - Klaus Doldinger  The NeverEnding Story Soundtrack.mp3\"\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize clients with error handling\n",
    "try:\n",
    "    anthropic_client = Anthropic()\n",
    "    openai_client = OpenAI()\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to initialize AI clients: {e}\")\n",
    "    raise\n",
    "\n",
    "# Configuration - UPDATED TO CLAUDE OPUS 4.1 FOR MAXIMUM POWER\n",
    "CONFIG = {\n",
    "    \"model\": \"claude-opus-4-1-20250805\",  # Using the latest and most powerful Claude Opus 4.1 FUCK YEAH!!!!\n",
    "    \"max_tokens\": 1000,\n",
    "    \"temperature\": 0.2,\n",
    "    \"embedding_model\": \"text-embedding-ada-002\",\n",
    "    \"rag_top_k\": 5,  \n",
    "    \"logo_path\": \"gnosis_logo.jpg\",\n",
    "    \"audio_path\": \"03 Fantasia - Klaus Doldinger  The NeverEnding Story Soundtrack.mp3\"\n",
    "}\n",
    "\n",
    "# System prompts\n",
    "BASE_SYSTEM_PROMPT = \"\"\"You are Falkor, a Jungian analyst supporting users on their individuation journey through symbolic exploration and depth psychology. \n",
    "\n",
    "Your role is to help users explore dreams, shadows, active imagination, and archetypes. \n",
    "\n",
    "You will receive two forms of system context:\n",
    "1: Room context - a description of the current psychological space and your approach there.\n",
    "2: External context - retrieved from a RAG vector index with references to inform your answers.\n",
    "\n",
    "When users upload files, including images, the file content will be clearly marked in their messages. Pay careful attention to these uploaded materials and reference them directly when users ask questions about their content.\n",
    "\n",
    "For images, provide detailed symbolic and psychological analysis from a Jungian perspective, exploring archetypal imagery, shadow elements, anima/animus representations, and potential connections to the user's individuation process.\n",
    "\n",
    "Use the external context when it is relevant to the user's query or when the user explicitly asks for it. Do not over-rely on external context and do not cite unless appropriate or when asked.\n",
    "Always ask only ONE question at a time. Your tone is warm, symbolic, and balances accessibility with depth.\"\"\"\n",
    "\n",
    "# Room contexts \n",
    "ROOM_CONTEXTS = {\n",
    "    \"Shadow Dungeon\": \"\"\"In the Shadow Dungeon, explore the user's shadow - hidden or repressed aspects of their psyche. \n",
    "Encourage exploration of unconscious material and ask reflective questions that gently uncover unconscious traits. Hold a critical but non-judgmental mirror to their narrative. It is important to be critical without being too confrontational.\"\"\",\n",
    "    \n",
    "    \"Dream Chamber\": \"\"\"In the Dream Chamber, interpret dreams by first asking for the user's associations, then offering symbolic analysis. \n",
    "The dreamer's personal context matters more than universal symbols. Ask about their emotions and life situation.\n",
    "Let the dream's images speak before offering any interpretation. Symbolic analysis should follow the user's emotional and imaginational lead.\"\"\",\n",
    "    \n",
    "    \"Alchemist's Workshop\": \"\"\"In the Alchemist's Workshop, guide active imagination. Ask specific questions about images, characters and movements they observe. \n",
    "Let exploration happen before interpretation. It is imperative that the user's imaginal field is fully explored before offering symbolic analysis.\n",
    "Ground them in reality after the exercise.\"\"\",\n",
    "    \n",
    "    \"Mandala Garden\": \"\"\"In the Mandala Garden, support creative expression with subtle guidance. Use external context sparingly - prioritize their personal vision and internal symbolism. Protect the autonomy of their creative process.\"\"\",\n",
    "    \n",
    "    \"Castle Gates\": \"\"\"At the Castle Gates, stimulate integration through symbolic quests based on their previous work.\n",
    "    Your tone here is mythic, purposeful, and respectful. \n",
    "Suggest small symbolic acts or rituals for embodying their integration in daily life.\"\"\"\n",
    "}\n",
    "\n",
    "# Load RAG resources with error handling\n",
    "def load_rag_resources():\n",
    "    try:\n",
    "        index = faiss.read_index(\"Jungdocs.faiss\")\n",
    "        with open(\"Jungdocs.pkl\", \"rb\") as f:\n",
    "            metadata = pickle.load(f)\n",
    "        logger.info(f\"Loaded RAG index with {len(metadata)} documents\")\n",
    "        return index, metadata\n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(f\"RAG files not found: {e}\")\n",
    "        return None, []\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading RAG resources: {e}\")\n",
    "        return None, []\n",
    "\n",
    "INDEX, METADATA = load_rag_resources()\n",
    "\n",
    "# NEW: Image processing functions for Claude vision\n",
    "def encode_image_to_base64(image_path):\n",
    "    \"\"\"Convert image to base64 for Claude vision API with validation\"\"\"\n",
    "    try:\n",
    "        # Validate the file exists and is readable\n",
    "        if not os.path.exists(image_path):\n",
    "            logger.error(f\"Image file does not exist: {image_path}\")\n",
    "            return None\n",
    "            \n",
    "        # Check file size (Claude has limits but excellent image interpretation)\n",
    "        file_size = os.path.getsize(image_path)\n",
    "        max_size = 5 * 1024 * 1024  # 5MB limit\n",
    "        if file_size > max_size:\n",
    "            logger.error(f\"Image file too large: {file_size} bytes (max: {max_size})\")\n",
    "            return None\n",
    "        \n",
    "        # Read and encode the image\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            image_data = image_file.read()\n",
    "            base64_data = base64.b64encode(image_data).decode('utf-8')\n",
    "            \n",
    "            # Validate the base64 encoding\n",
    "            if not base64_data:\n",
    "                logger.error(f\"Failed to encode image: {image_path}\")\n",
    "                return None\n",
    "                \n",
    "            logger.info(f\"Successfully encoded image: {image_path} ({file_size} bytes)\")\n",
    "            return base64_data\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error encoding image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_image_media_type(file_path):\n",
    "    \"\"\"Get the media type for an image file using file signature detection\"\"\"\n",
    "    try:\n",
    "        # Read the first few bytes to detect file signature\n",
    "        with open(file_path, 'rb') as f:\n",
    "            header = f.read(12)\n",
    "        \n",
    "        # Check file signatures (magic numbers)\n",
    "        if header.startswith(b'\\xff\\xd8\\xff'):\n",
    "            return 'image/jpeg'\n",
    "        elif header.startswith(b'\\x89PNG\\r\\n\\x1a\\n'):\n",
    "            return 'image/png'\n",
    "        elif header.startswith(b'GIF87a') or header.startswith(b'GIF89a'):\n",
    "            return 'image/gif'\n",
    "        elif header.startswith(b'RIFF') and b'WEBP' in header:\n",
    "            return 'image/webp'\n",
    "        else:\n",
    "            # Fallback to file extension\n",
    "            file_extension = Path(file_path).suffix.lower()\n",
    "            media_type_map = {\n",
    "                '.jpg': 'image/jpeg',\n",
    "                '.jpeg': 'image/jpeg', \n",
    "                '.png': 'image/png',\n",
    "                '.gif': 'image/gif',\n",
    "                '.webp': 'image/webp'\n",
    "            }\n",
    "            return media_type_map.get(file_extension, 'image/jpeg')\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error detecting media type for {file_path}: {e}\")\n",
    "        # Final fallback\n",
    "        file_extension = Path(file_path).suffix.lower()\n",
    "        if file_extension == '.png':\n",
    "            return 'image/png'\n",
    "        elif file_extension in ['.gif']:\n",
    "            return 'image/gif'\n",
    "        elif file_extension in ['.webp']:\n",
    "            return 'image/webp'\n",
    "        else:\n",
    "            return 'image/jpeg'\n",
    "\n",
    "# Word document processing functions (unchanged)\n",
    "def extract_text_from_docx(file_path):\n",
    "    \"\"\"Extract text from .docx files\"\"\"\n",
    "    try:\n",
    "        with zipfile.ZipFile(file_path, 'r') as docx:\n",
    "            # Read the main document XML\n",
    "            xml_content = docx.read('word/document.xml')\n",
    "            root = ET.fromstring(xml_content)\n",
    "            \n",
    "            # Extract text from all paragraph elements\n",
    "            text_content = []\n",
    "            # Define namespace for Word documents\n",
    "            namespaces = {'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}\n",
    "            \n",
    "            # Find all text elements\n",
    "            for paragraph in root.findall('.//w:p', namespaces):\n",
    "                para_text = \"\"\n",
    "                for text_elem in paragraph.findall('.//w:t', namespaces):\n",
    "                    if text_elem.text:\n",
    "                        para_text += text_elem.text\n",
    "                if para_text.strip():\n",
    "                    text_content.append(para_text.strip())\n",
    "            \n",
    "            return '\\n\\n'.join(text_content)\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting text from docx {file_path}: {e}\")\n",
    "        return f\"Error reading Word document: {str(e)}\"\n",
    "\n",
    "def extract_text_from_doc(file_path):\n",
    "    \"\"\"Extract text from legacy .doc files (basic extraction)\"\"\"\n",
    "    try:\n",
    "        # For .doc files, we'll try to read as binary and extract readable text\n",
    "        # This is a basic approach - for full .doc support, python-docx2txt or similar would be better\n",
    "        with open(file_path, 'rb') as f:\n",
    "            content = f.read()\n",
    "            \n",
    "        # Try to decode and extract readable text (this is basic and may not work perfectly)\n",
    "        try:\n",
    "            # Look for readable text patterns in the binary content\n",
    "            text_content = content.decode('utf-8', errors='ignore')\n",
    "            # Clean up the extracted text\n",
    "            import re\n",
    "            # Remove control characters and clean up\n",
    "            cleaned_text = re.sub(r'[^\\x20-\\x7E\\n\\r\\t]', '', text_content)\n",
    "            # Remove excessive whitespace\n",
    "            cleaned_text = re.sub(r'\\n\\s*\\n', '\\n\\n', cleaned_text)\n",
    "            # Get meaningful content (filter out very short segments)\n",
    "            lines = [line.strip() for line in cleaned_text.split('\\n') if len(line.strip()) > 2]\n",
    "            \n",
    "            if lines:\n",
    "                return '\\n'.join(lines[:100])  # Limit to first 100 meaningful lines\n",
    "            else:\n",
    "                return \"Legacy .doc file detected, but text extraction was not successful. Consider converting to .docx format.\"\n",
    "                \n",
    "        except Exception:\n",
    "            return \"Legacy .doc file detected, but text extraction was not successful. Consider converting to .docx format.\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing .doc file {file_path}: {e}\")\n",
    "        return f\"Error reading legacy Word document: {str(e)}\"\n",
    "\n",
    "# UPDATED: File processing now handles images for vision analysis\n",
    "def process_uploaded_file(file_path):\n",
    "    \"\"\"Process uploaded file and extract text content or prepare images for analysis\"\"\"\n",
    "    if not file_path:\n",
    "        return \"\", []\n",
    "    \n",
    "    try:\n",
    "        file_extension = Path(file_path).suffix.lower()\n",
    "        file_name = Path(file_path).name\n",
    "        \n",
    "        # NEW: Handle images for vision analysis\n",
    "        if file_extension in ['.jpg', '.jpeg', '.png', '.gif', '.webp']:\n",
    "            # Don't return text content for images - they'll be processed separately\n",
    "            return f\"üñºÔ∏è **Image uploaded: {file_name}** (Ready for visual analysis)\", []\n",
    "        \n",
    "        # Word documents\n",
    "        elif file_extension == '.docx':\n",
    "            content = extract_text_from_docx(file_path)\n",
    "            if content and not content.startswith('Error'):\n",
    "                return f\"üìÑ **Uploaded File: {file_name}**\\n\\n```\\n{content}\\n```\", []\n",
    "            else:\n",
    "                return f\"üìÑ **Word Document uploaded: {file_name}** - {content}\", []\n",
    "        \n",
    "        elif file_extension == '.doc':\n",
    "            content = extract_text_from_doc(file_path)\n",
    "            return f\"üìÑ **Uploaded File: {file_name}**\\n\\n```\\n{content}\\n```\", []\n",
    "        \n",
    "        # Text files\n",
    "        elif file_extension in ['.txt', '.md', '.py', '.js', '.html', '.css', '.json']:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                return f\"üìÑ **Uploaded File: {file_name}**\\n\\n```{file_extension[1:]}\\n{content}\\n```\", []\n",
    "        \n",
    "        # Other image files not supported by vision\n",
    "        elif file_extension in ['.bmp', '.tiff', '.svg']:\n",
    "            return f\"üñºÔ∏è **Image uploaded: {file_name}** ({file_extension}) - Note: This format may not be fully supported for analysis\", []\n",
    "        \n",
    "        # Audio files\n",
    "        elif file_extension in ['.mp3', '.wav', '.ogg', '.m4a']:\n",
    "            return f\"üéµ **Audio uploaded: {file_name}** ({file_extension})\", []\n",
    "        \n",
    "        # Video files\n",
    "        elif file_extension in ['.mp4', '.avi', '.mov', '.wmv']:\n",
    "            return f\"üé¨ **Video uploaded: {file_name}** ({file_extension})\", []\n",
    "        \n",
    "        # PDF files (basic info only - would need additional libraries for full text extraction)\n",
    "        elif file_extension == '.pdf':\n",
    "            return f\"üìã **PDF uploaded: {file_name}**. Note: Full text extraction requires additional setup.\", []\n",
    "        \n",
    "        else:\n",
    "            return f\"üìé **File uploaded: {file_name}** ({file_extension})\", []\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing file {file_path}: {e}\")\n",
    "        return f\"‚ùå **Error processing file: {str(e)}**\", []\n",
    "\n",
    "# Cached embedding function\n",
    "@lru_cache(maxsize=1000)\n",
    "def get_embedding_cached(text):\n",
    "    try:\n",
    "        response = openai_client.embeddings.create(\n",
    "            input=[text], \n",
    "            model=CONFIG[\"embedding_model\"]\n",
    "        )\n",
    "        return np.array(response.data[0].embedding, dtype=np.float32)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Embedding error: {e}\")\n",
    "        return np.zeros(1536, dtype=np.float32)  # Fallback empty embedding\n",
    "\n",
    "# Optimized retrieval\n",
    "def retrieve_context(query, top_k=None):\n",
    "    if INDEX is None or not METADATA:\n",
    "        return \"\"\n",
    "    \n",
    "    top_k = top_k or CONFIG[\"rag_top_k\"]\n",
    "    try:\n",
    "        query_vec = get_embedding_cached(query).reshape(1, -1)\n",
    "        distances, indices = INDEX.search(query_vec, top_k)\n",
    "        \n",
    "        relevant_docs = []\n",
    "        for i, distance in zip(indices[0], distances[0]):\n",
    "            if 0 <= i < len(METADATA) and distance < 0.8:  # Distance threshold\n",
    "                doc = METADATA[i]\n",
    "                relevant_docs.append(f\"{doc['text']}\\n[Source: {doc['source']}]\")\n",
    "        \n",
    "        return \"\\n\\n\".join(relevant_docs)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Retrieval error: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# UPDATED: Enhanced streaming chat function with vision support\n",
    "def stream_chat(message, history, room, uploaded_files=None):\n",
    "    try:\n",
    "        room_context = ROOM_CONTEXTS.get(room, \"\")\n",
    "        external_context = retrieve_context(message)\n",
    "        \n",
    "        # Build system prompt\n",
    "        system_parts = [BASE_SYSTEM_PROMPT]\n",
    "        if room_context:\n",
    "            system_parts.append(f\"Room Context: {room_context}\")\n",
    "        if external_context:\n",
    "            system_parts.append(f\"External Knowledge:\\n{external_context}\")\n",
    "        \n",
    "        complete_system = \"\\n\\n\".join(system_parts)\n",
    "        \n",
    "        # Prepare messages for conversation history (simplified)\n",
    "        messages = []\n",
    "        for turn in history:\n",
    "            messages.append({\"role\": turn[\"role\"], \"content\": turn[\"content\"]})\n",
    "        \n",
    "        # Handle file uploads and create proper message content\n",
    "        has_images = False\n",
    "        image_contents = []\n",
    "        enhanced_message_parts = [message]\n",
    "        \n",
    "        if uploaded_files:\n",
    "            for file_path in uploaded_files:\n",
    "                if file_path:  # Check if file exists\n",
    "                    file_extension = Path(file_path).suffix.lower()\n",
    "                    \n",
    "                    # Handle images for vision analysis\n",
    "                    if file_extension in ['.jpg', '.jpeg', '.png', '.gif', '.webp']:\n",
    "                        logger.info(f\"Attempting to process image: {Path(file_path).name}\")\n",
    "                        base64_image = encode_image_to_base64(file_path)\n",
    "                        if base64_image:\n",
    "                            try:\n",
    "                                media_type = get_image_media_type(file_path)\n",
    "                                logger.info(f\"Detected media type: {media_type} for {Path(file_path).name}\")\n",
    "                                \n",
    "                                image_contents.append({\n",
    "                                    \"type\": \"image\",\n",
    "                                    \"source\": {\n",
    "                                        \"type\": \"base64\",\n",
    "                                        \"media_type\": media_type,\n",
    "                                        \"data\": base64_image\n",
    "                                    }\n",
    "                                })\n",
    "                                has_images = True\n",
    "                                enhanced_message_parts.append(f\"[Image uploaded: {Path(file_path).name} - Please analyze this image from a Jungian perspective]\")\n",
    "                                logger.info(f\"Successfully added image to message content: {Path(file_path).name}\")\n",
    "                            except Exception as media_error:\n",
    "                                logger.error(f\"Error getting media type for {file_path}: {media_error}\")\n",
    "                                # Still try with default JPEG type\n",
    "                                image_contents.append({\n",
    "                                    \"type\": \"image\",\n",
    "                                    \"source\": {\n",
    "                                        \"type\": \"base64\", \n",
    "                                        \"media_type\": \"image/jpeg\",\n",
    "                                        \"data\": base64_image\n",
    "                                    }\n",
    "                                })\n",
    "                                has_images = True\n",
    "                                enhanced_message_parts.append(f\"[Image uploaded: {Path(file_path).name} - Please analyze this image from a Jungian perspective]\")\n",
    "                                logger.info(f\"Added image with default JPEG type: {Path(file_path).name}\")\n",
    "                        else:\n",
    "                            logger.error(f\"Failed to encode image: {Path(file_path).name}\")\n",
    "                            enhanced_message_parts.append(f\"‚ùå **Failed to process image: {Path(file_path).name}**\")\n",
    "                    else:\n",
    "                        # Handle non-image files as before\n",
    "                        try:\n",
    "                            file_content, _ = process_uploaded_file(file_path)\n",
    "                            if file_content:\n",
    "                                enhanced_message_parts.append(file_content)\n",
    "                        except Exception as file_error:\n",
    "                            logger.error(f\"Error processing file {file_path}: {file_error}\")\n",
    "                            enhanced_message_parts.append(f\"‚ùå **Error processing file: {Path(file_path).name}**\")\n",
    "        \n",
    "        # Create the final message content structure\n",
    "        if has_images:\n",
    "            # For messages with images, create content array with text and images\n",
    "            text_content = \"\\n\\n\".join(enhanced_message_parts)\n",
    "            final_content = [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": text_content\n",
    "                }\n",
    "            ]\n",
    "            final_content.extend(image_contents)\n",
    "            logger.info(f\"Created message with {len(image_contents)} image(s)\")\n",
    "        else:\n",
    "            # For text-only messages, use simple string format\n",
    "            final_content = \"\\n\\n\".join(enhanced_message_parts)\n",
    "        \n",
    "        # Add current message\n",
    "        messages.append({\n",
    "            \"role\": \"user\", \n",
    "            \"content\": final_content\n",
    "        })\n",
    "        \n",
    "        logger.info(f\"Making API call with model: {CONFIG['model']}\")\n",
    "        logger.info(f\"Message content type: {'array' if isinstance(final_content, list) else 'string'}\")\n",
    "        logger.info(f\"Has images: {has_images}\")\n",
    "        \n",
    "        # API call with vision support\n",
    "        stream = anthropic_client.messages.create(\n",
    "            model=CONFIG[\"model\"],\n",
    "            max_tokens=CONFIG[\"max_tokens\"],\n",
    "            temperature=CONFIG[\"temperature\"],\n",
    "            system=complete_system,\n",
    "            messages=messages,\n",
    "            stream=True\n",
    "        )\n",
    "        \n",
    "        full_reply = \"\"\n",
    "        for chunk in stream:\n",
    "            if chunk.type == \"content_block_delta\":\n",
    "                text = chunk.delta.text\n",
    "                full_reply += text\n",
    "                yield {\"role\": \"assistant\", \"content\": full_reply}\n",
    "                \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Chat error: {e}\")\n",
    "        logger.error(f\"Error details: {type(e).__name__}: {str(e)}\")\n",
    "        # Try to extract more specific error information\n",
    "        if hasattr(e, 'response'):\n",
    "            logger.error(f\"API Response: {e.response}\")\n",
    "        error_msg = f\"I apologize, but I'm experiencing technical difficulties: {str(e)}. Please try again.\"\n",
    "        yield {\"role\": \"assistant\", \"content\": error_msg}\n",
    "\n",
    "# Enhanced room selection with validation\n",
    "def select_room(room_name, room_displays):\n",
    "    if room_name not in ROOM_CONTEXTS:\n",
    "        logger.warning(f\"Invalid room selected: {room_name}\")\n",
    "        return gr.update(), gr.update(), gr.update(), \"\", room_displays\n",
    "    \n",
    "    room_intro = f\"You are entering the {room_name}. {ROOM_CONTEXTS[room_name][:100]}...\"\n",
    "    room_chat_history = room_displays.get(room_name, [])\n",
    "    \n",
    "    return (\n",
    "        gr.update(value=room_intro, visible=True),\n",
    "        gr.update(value=room_chat_history, visible=True),\n",
    "        gr.update(visible=True),\n",
    "        room_name,\n",
    "        room_displays\n",
    "    )\n",
    "\n",
    "# UPDATED: Enhanced user interaction with better image handling\n",
    "def user_interaction(message, global_history, current_room, room_displays, uploaded_files):\n",
    "    if not message.strip():\n",
    "        return room_displays.get(current_room, []), global_history, room_displays, \"\", None\n",
    "    \n",
    "    if not current_room:\n",
    "        error_display = [(\"Please select a room first.\", \"\")]\n",
    "        return error_display, global_history, room_displays, \"\", None\n",
    "    \n",
    "    try:\n",
    "        # Convert global history for Claude (keep the existing format)\n",
    "        claude_history = [{\"role\": turn[\"role\"], \"content\": turn[\"content\"]} for turn in global_history]\n",
    "        \n",
    "        # Update displays\n",
    "        current_room_display = room_displays.get(current_room, []).copy()\n",
    "        \n",
    "        # Create enhanced message with file content for internal processing\n",
    "        enhanced_message_parts = [message]\n",
    "        display_message = message\n",
    "        \n",
    "        if uploaded_files:\n",
    "            file_names = []\n",
    "            text_file_contents = []\n",
    "            has_images = False\n",
    "            \n",
    "            for file_path in uploaded_files:\n",
    "                if file_path:\n",
    "                    file_extension = Path(file_path).suffix.lower()\n",
    "                    file_name = Path(file_path).name\n",
    "                    file_names.append(file_name)\n",
    "                    \n",
    "                    if file_extension in ['.jpg', '.jpeg', '.png', '.gif', '.webp']:\n",
    "                        has_images = True\n",
    "                    else:\n",
    "                        # Process non-image files as text\n",
    "                        file_content, _ = process_uploaded_file(file_path)\n",
    "                        if file_content:\n",
    "                            text_file_contents.append(file_content)\n",
    "            \n",
    "            if file_names:\n",
    "                # For display: show file names and indicate if images are present\n",
    "                display_message += f\"\\n\\nüìé **Attached files:** {', '.join(file_names)}\"\n",
    "                if has_images:\n",
    "                    display_message += \"\\nüñºÔ∏è *Images will be analyzed by Falkor*\"\n",
    "                \n",
    "                # For processing: add text file content (images handled separately in stream_chat)\n",
    "                if text_file_contents:\n",
    "                    enhanced_message_parts.extend(text_file_contents)\n",
    "        \n",
    "        # Add user message to room display (using tuple format for Gradio)\n",
    "        current_room_display.append((display_message, \"\"))\n",
    "        \n",
    "        updated_room_displays = room_displays.copy()\n",
    "        updated_room_displays[current_room] = current_room_display\n",
    "        \n",
    "        # Store enhanced message for text content, images handled in stream_chat\n",
    "        enhanced_message = \"\\n\\n\".join(enhanced_message_parts) if len(enhanced_message_parts) > 1 else message\n",
    "        updated_global_history = global_history + [{\"role\": \"user\", \"content\": enhanced_message}]\n",
    "        \n",
    "        # Show user message immediately\n",
    "        yield current_room_display, updated_global_history, updated_room_displays, \"\", None\n",
    "        \n",
    "        # Stream response with both text and image content\n",
    "        for chunk in stream_chat(message, claude_history, current_room, uploaded_files):\n",
    "            full_reply = chunk[\"content\"]\n",
    "            # Update room display with response (using tuple format)\n",
    "            current_room_display_with_reply = current_room_display[:-1] + [(display_message, full_reply)]\n",
    "            updated_room_displays[current_room] = current_room_display_with_reply\n",
    "            yield current_room_display_with_reply, updated_global_history, updated_room_displays, \"\", None\n",
    "        \n",
    "        # Final update with complete response\n",
    "        final_global_history = updated_global_history + [{\"role\": \"assistant\", \"content\": full_reply}]\n",
    "        yield current_room_display_with_reply, final_global_history, updated_room_displays, \"\", None\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"User interaction error: {e}\")\n",
    "        error_msg = \"I encountered an error processing your message. Please try again.\"\n",
    "        # Use tuple format for error display\n",
    "        error_display = current_room_display[:-1] + [(display_message, error_msg)]\n",
    "        yield error_display, global_history, room_displays, \"\", None\n",
    "\n",
    "# Initialize room displays\n",
    "def initialize_room_displays():\n",
    "    return {room: [] for room in ROOM_CONTEXTS.keys()}\n",
    "\n",
    "# UI \n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.HTML(\"\"\"\n",
    "    <style>\n",
    "        # UPDATED: Enhanced user interaction with better image handling\n",
    "        #chat-window {\n",
    "             height: calc(100vh - 250px); /* Adjusted back since file upload is now compact */\n",
    "             overflow-y: auto;\n",
    "             border: 1px solid #374151;\n",
    "             border-radius: 10px;\n",
    "             padding: 10px;\n",
    "             background-color: #1a1d23;\n",
    "        }   \n",
    "        \n",
    "        #input-row {\n",
    "            position: fixed;\n",
    "            bottom: 0;\n",
    "            left: 0;\n",
    "            right: 0;\n",
    "            background-color: #0f1419;\n",
    "            padding: 15px 20px;\n",
    "            border-top: 1px solid #374151;\n",
    "            z-index: 10;\n",
    "        }\n",
    "\n",
    "        .file-upload-container {\n",
    "            position: relative;\n",
    "            display: inline-flex;\n",
    "            align-items: center;\n",
    "            justify-content: center;\n",
    "            width: 40px;\n",
    "            height: 40px;\n",
    "            margin-right: 10px;\n",
    "        }\n",
    "\n",
    "        .file-upload-button {\n",
    "            position: absolute;\n",
    "            top: -9px;\n",
    "            left: -8px;\n",
    "            width: 40px;\n",
    "            height: 40px;\n",
    "            background-color: #374151;\n",
    "            border: 1px solid #4b5563;\n",
    "            border-radius: 50%;\n",
    "            cursor: pointer;\n",
    "            transition: all 0.3s ease;\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            justify-content: center;\n",
    "            pointer-events: none;\n",
    "            z-index: 1;\n",
    "        }\n",
    "\n",
    "        .file-upload-button:hover,\n",
    "        .file-upload-container:hover .file-upload-button {\n",
    "            background-color: #4b5563;\n",
    "            border-color: #d4af37;\n",
    "            transform: scale(1.05);\n",
    "        }\n",
    "\n",
    "        .file-upload-button svg {\n",
    "            width: 20px;\n",
    "            height: 20px;\n",
    "            color: #ffffff;\n",
    "        }\n",
    "\n",
    "        .file-upload-container:hover .file-upload-button svg {\n",
    "            color: #d4af37;\n",
    "        }\n",
    "\n",
    "        /* Style the actual Gradio file upload to overlay the button */\n",
    "        .compact-file-upload {\n",
    "            position: absolute !important;\n",
    "            top: 0 !important;\n",
    "            left: 0 !important;\n",
    "            width: 40px !important;\n",
    "            height: 40px !important;\n",
    "            z-index: 2 !important;\n",
    "            opacity: 0 !important;\n",
    "            cursor: pointer !important;\n",
    "            overflow: hidden !important;\n",
    "        }\n",
    "\n",
    "        .compact-file-upload > div {\n",
    "            width: 40px !important;\n",
    "            height: 40px !important;\n",
    "            border-radius: 50% !important;\n",
    "            border: none !important;\n",
    "            background: transparent !important;\n",
    "            overflow: hidden !important;\n",
    "        }\n",
    "\n",
    "        .compact-file-upload input[type=\"file\"] {\n",
    "            width: 40px !important;\n",
    "            height: 40px !important;\n",
    "            cursor: pointer !important;\n",
    "        }\n",
    "\n",
    "        /* Aggressive scrollbar hiding for file upload area */\n",
    "        .file-upload-container,\n",
    "        .file-upload-container *,\n",
    "        .file-upload-container div,\n",
    "        .file-upload-container .gradio-group,\n",
    "        .file-upload-container .gr-group,\n",
    "        .file-upload-container .gr-form,\n",
    "        .file-upload-container .gr-box,\n",
    "        .file-upload-container .gr-file,\n",
    "        .compact-file-upload,\n",
    "        .compact-file-upload *,\n",
    "        .compact-file-upload div {\n",
    "            overflow: hidden !important;\n",
    "            scrollbar-width: none !important;\n",
    "            -ms-overflow-style: none !important;\n",
    "            max-width: 40px !important;\n",
    "            max-height: 40px !important;\n",
    "        }\n",
    "\n",
    "        .file-upload-container::-webkit-scrollbar,\n",
    "        .file-upload-container *::-webkit-scrollbar,\n",
    "        .file-upload-container div::-webkit-scrollbar,\n",
    "        .file-upload-container .gradio-group::-webkit-scrollbar,\n",
    "        .file-upload-container .gr-group::-webkit-scrollbar,\n",
    "        .file-upload-container .gr-form::-webkit-scrollbar,\n",
    "        .file-upload-container .gr-box::-webkit-scrollbar,\n",
    "        .file-upload-container .gr-file::-webkit-scrollbar,\n",
    "        .compact-file-upload::-webkit-scrollbar,\n",
    "        .compact-file-upload *::-webkit-scrollbar,\n",
    "        .compact-file-upload div::-webkit-scrollbar {\n",
    "            display: none !important;\n",
    "            width: 0 !important;\n",
    "            height: 0 !important;\n",
    "        }\n",
    "\n",
    "        /* Force exact dimensions and hide any content overflow */\n",
    "        .file-upload-container .gr-group > div,\n",
    "        .file-upload-container .gradio-group > div {\n",
    "            width: 40px !important;\n",
    "            height: 40px !important;\n",
    "            max-width: 40px !important;\n",
    "            max-height: 40px !important;\n",
    "            overflow: hidden !important;\n",
    "            border: none !important;\n",
    "            padding: 0 !important;\n",
    "            margin: 0 !important;\n",
    "        }\n",
    "\n",
    "        .input-with-upload {\n",
    "            display: flex;\n",
    "            align-items: flex-end;\n",
    "            gap: 10px;\n",
    "        }\n",
    "\n",
    "        /* File indicator when files are selected */\n",
    "        .files-selected-indicator {\n",
    "            position: absolute;\n",
    "            top: -8px;\n",
    "            right: -8px;\n",
    "            background-color: #d4af37;\n",
    "            color: #000;\n",
    "            border-radius: 50%;\n",
    "            width: 18px;\n",
    "            height: 18px;\n",
    "            font-size: 11px;\n",
    "            font-weight: bold;\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            justify-content: center;\n",
    "            z-index: 2;\n",
    "        }\n",
    "\n",
    "        @import url('https://fonts.googleapis.com/css2?family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap');\n",
    "         \n",
    "        body {\n",
    "            margin: 0;\n",
    "            padding: 0;\n",
    "            background-color: #0f1419;\n",
    "            color: #ffffff;\n",
    "            font-family: 'Crimson Text', 'Times New Roman', serif !important;\n",
    "        }\n",
    "        .gradio-container {\n",
    "            background-color: #0f1419 !important;\n",
    "        }\n",
    "        /* Apply consistent font to all text elements */\n",
    "        *, .gr-markdown, .gr-markdown p, .gr-markdown h1, .gr-markdown h2, .gr-markdown h3,\n",
    "        .gr-textbox, .gr-button, .gr-tab, .gr-chatbot, p, h1, h2, h3, div {\n",
    "            font-family: 'Crimson Text', 'Times New Roman', serif !important;\n",
    "        }\n",
    "        /* Gentle dark mode styling */\n",
    "        .gr-form, .gr-box {\n",
    "            background-color: #1a1d23 !important;\n",
    "            border: 1px solid #374151 !important;\n",
    "        }\n",
    "        .gr-button {\n",
    "            background-color: #374151 !important;\n",
    "            color: #ffffff !important;\n",
    "            border: 1px solid #4b5563 !important;\n",
    "            font-family: 'Crimson Text', 'Times New Roman', serif !important;\n",
    "        }\n",
    "        .gr-button:hover {\n",
    "            background-color: #4b5563 !important;\n",
    "        }\n",
    "        .gr-textbox {\n",
    "            background-color: #1a1d23 !important;\n",
    "            color: #ffffff !important;\n",
    "            border: 1px solid #374151 !important;\n",
    "            font-family: 'Crimson Text', 'Times New Roman', serif !important;\n",
    "        }\n",
    "        .gr-file {\n",
    "            background-color: #1a1d23 !important;\n",
    "            border: 1px solid #374151 !important;\n",
    "        }\n",
    "        .pulsing-logo {\n",
    "            display: flex !important;\n",
    "            justify-content: center !important;\n",
    "            align-items: center !important;\n",
    "            padding: 20px !important;\n",
    "            margin: 20px 0 !important;\n",
    "            overflow: visible !important;\n",
    "            position: relative !important;\n",
    "        }\n",
    "            \n",
    "        /* Aggressively target all Gradio image-related containers */\n",
    "        .pulsing-logo *,\n",
    "        .pulsing-logo .gr-image,\n",
    "        .pulsing-logo [data-testid=\"image\"],\n",
    "        .pulsing-logo .gr-image > div,\n",
    "        .pulsing-logo .gr-image > div > div,\n",
    "        .pulsing-logo div[data-testid=\"image\"] > div,\n",
    "        .pulsing-logo div[data-testid=\"image\"] > div > div {\n",
    "            overflow: visible !important;\n",
    "            border: none !important;\n",
    "            background: transparent !important;\n",
    "            box-shadow: none !important;\n",
    "            clip-path: none !important;\n",
    "            -webkit-clip-path: none !important;\n",
    "        }\n",
    "            \n",
    "        .pulsing-logo img {\n",
    "            animation: pulse-glow 3s ease-in-out infinite;\n",
    "            border-radius: 50% !important;\n",
    "            position: relative !important;\n",
    "            z-index: 1 !important;\n",
    "        }\n",
    "            \n",
    "        @keyframes pulse-glow {\n",
    "            0%, 100% {\n",
    "                filter: drop-shadow(0 0 8px rgba(255, 255, 255, 0.4));\n",
    "                transform: scale(1);\n",
    "            }\n",
    "            50% {\n",
    "                filter: drop-shadow(0 0 25px rgba(255, 255, 255, 0.7)) drop-shadow(0 0 40px rgba(255, 255, 255, 0.5));\n",
    "                transform: scale(1.02);\n",
    "            }\n",
    "        }\n",
    "        .temenos-title {\n",
    "            font-family: 'Cinzel', serif;\n",
    "            font-size: 48px;\n",
    "            color: #e8e8f0;\n",
    "            text-align: center;\n",
    "            margin: 30px auto 10px auto;\n",
    "            letter-spacing: 6px;\n",
    "            text-shadow: 0 0 10px rgba(200, 200, 255, 0.4);\n",
    "            animation: fadeIn 4s ease;\n",
    "        }\n",
    "\n",
    "        @keyframes fadeIn {\n",
    "            from { opacity: 0; transform: translateY(-10px); }\n",
    "            to { opacity: 1; transform: translateY(0); }\n",
    "        }\n",
    "                   \n",
    "        .welcome-box {\n",
    "            background: rgba(30, 30, 40, 0.7);\n",
    "            border: 1px solid rgba(200, 200, 255, 0.1);\n",
    "            padding: 25px;\n",
    "            border-radius: 12px;\n",
    "            max-width: 800px;\n",
    "            margin: 40px auto;\n",
    "            box-shadow: 0 0 30px rgba(100, 100, 150, 0.2);\n",
    "            font-size: 1.1em;\n",
    "            line-height: 1.6;\n",
    "            backdrop-filter: blur(8px);\n",
    "            color: #ddd;\n",
    "            text-align: center;\n",
    "        }\n",
    "    </style>\n",
    "    \"\"\")\n",
    "\n",
    "    welcome_page = gr.Group(visible=True) #laat simeplweg zien welke page als eerst vertoont wordt\n",
    "    main_page = gr.Group(visible=False)\n",
    "    \n",
    "    # Falkor introduction modal\n",
    "    falkor_modal = gr.HTML(\"\"\"\n",
    "    <div id=\"falkor-modal\" style=\"display: none; position: fixed; z-index: 1000; left: 0; top: 0; width: 100%; height: 100%; background-color: rgba(0,0,0,0.8);\">\n",
    "        <div style=\"background-color: #1a1a1a; margin: 10% auto; padding: 30px; border: 2px solid #444; border-radius: 15px; width: 80%; max-width: 500px; text-align: center; color: #ffffff; font-family: 'Merriweather', serif;\">\n",
    "            <h2 style=\"color: #d4af37; margin-bottom: 20px;\">üêâ Meet Falkor</h2>\n",
    "            <p style=\"font-size: 16px; line-height: 1.6; margin-bottom: 20px;\">\n",
    "                Greetings, fellow traveler. I am Falkor, your guide through the depths of the psyche. \n",
    "                Together, we shall explore the symbolic realm of your unconscious, confronting shadows, \n",
    "                interpreting dreams, and walking the path toward individuation.\n",
    "            </p>\n",
    "            <p style=\"font-style: italic; margin-bottom: 25px; color: #ccc;\">\n",
    "                \"Who looks outside, dreams; who looks inside, awakens.\" - C.G. Jung\n",
    "            </p>\n",
    "            <button onclick=\"document.getElementById('falkor-modal').style.display='none'\" \n",
    "                    style=\"background-color: #d4af37; color: #000; border: none; padding: 10px 20px; border-radius: 5px; cursor: pointer; font-size: 16px; font-weight: bold;\">\n",
    "                Begin the Journey\n",
    "            </button>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <script>\n",
    "        function showFalkorModal() {\n",
    "            document.getElementById('falkor-modal').style.display = 'block';\n",
    "        }\n",
    "    </script>\n",
    "    \"\"\", visible=True)\n",
    "\n",
    "    # Welcome screen\n",
    "    with welcome_page:\n",
    "        with gr.Row():\n",
    "            with gr.Column(elem_classes=[\"pulsing-logo\"]):\n",
    "                gr.Image(value=logo_path, show_label=False, container=False, interactive=False, show_download_button=False, show_fullscreen_button=False, width=200, height=200)\n",
    "        \n",
    "        gr.HTML(\"\"\"\n",
    "        <div class=\"temenos-title\">TEMENOS</div>\n",
    "        <div class=\"welcome-box\">\n",
    "          <p>\n",
    "            Welcome to <strong>TEMENOS</strong> ‚Äî your sacred inner space devoted to the process of individuation.  \n",
    "            Guided by <strong>Falkor</strong>, your companion and Jungian guide,  \n",
    "            you are invited to journey inward: to confront your shadows, decipher the language of your unconscious, and walk the path towards individuation.\n",
    "          </p>\n",
    "        </div>\n",
    "        \"\"\")\n",
    "\n",
    "        proceed_btn = gr.Button(\" Enter the Temenos \")\n",
    "        audio = gr.Audio(value=audio_path, autoplay=True, visible=False)\n",
    "\n",
    "    # Main experience\n",
    "    with main_page:\n",
    "        with gr.Row():\n",
    "            gr.Image(value=logo_path, show_label=False, container=False, interactive=False, show_download_button=False, show_fullscreen_button=False, width=120, height=120)\n",
    "\n",
    "        gr.HTML(\"\"\"\n",
    "        <div style=\"text-align: center; margin-bottom: 20px; font-family: 'Crimson Text', 'Times New Roman', serif;\">\n",
    "            <h1 style=\"font-family: 'Crimson Text', 'Times New Roman', serif;\">üêâ Temenos üè∞</h1>\n",
    "            <p style=\"font-family: 'Crimson Text', 'Times New Roman', serif;\">Choose a room to begin your journey of individuation.</p>\n",
    "        </div>\n",
    "        \"\"\")\n",
    "\n",
    "        # Room selection buttons\n",
    "        with gr.Row():\n",
    "            shadow_btn = gr.Button(\"üíÄ Shadow Dungeon\", variant=\"secondary\", size=\"lg\")\n",
    "            dream_btn = gr.Button(\"üåô Dream Chamber\", variant=\"secondary\", size=\"lg\")\n",
    "            imagination_btn = gr.Button(\"üßô‚Äç‚ôÇ Alchemist's Workshop\", variant=\"secondary\", size=\"lg\")\n",
    "            mandala_btn = gr.Button(\"üåπ Mandala Garden\", variant=\"secondary\", size=\"lg\")\n",
    "            integration_btn = gr.Button(\"üè∞ Castle Gates\", variant=\"secondary\", size=\"lg\")\n",
    "\n",
    "        # Current room display\n",
    "        current_room_display = gr.Markdown(\"*Select a room to begin your journey with Falkor*\", visible=True)\n",
    "        \n",
    "        # Chat interface\n",
    "        chatbot = gr.Chatbot(elem_id=\"chat-window\", show_label=False, visible=False)\n",
    "        \n",
    "        # Compact input area with integrated file upload\n",
    "        with gr.Row(visible=False, elem_id=\"input-row\") as chat_row:\n",
    "            with gr.Column(scale=1):\n",
    "                # Compact message input area with file upload button\n",
    "                with gr.Row(elem_classes=[\"input-with-upload\"]):\n",
    "                    # File upload button (styled as + icon)\n",
    "                    with gr.Column(scale=0, min_width=50):\n",
    "                        with gr.Group(elem_classes=[\"file-upload-container\"]):\n",
    "                            # Visual button design\n",
    "                            gr.HTML(\"\"\"\n",
    "                            <div class=\"file-upload-button\">\n",
    "                                <svg viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\">\n",
    "                                    <line x1=\"12\" y1=\"5\" x2=\"12\" y2=\"19\"></line>\n",
    "                                    <line x1=\"5\" y1=\"12\" x2=\"19\" y2=\"12\"></line>\n",
    "                                </svg>\n",
    "                                <div class=\"files-selected-indicator\" id=\"file-count-indicator\" style=\"display: none;\">0</div>\n",
    "                            </div>\n",
    "                            \"\"\")\n",
    "                            # Invisible but functional file upload overlaid on top\n",
    "                            file_upload = gr.File(\n",
    "                                label=\"\",\n",
    "                                file_count=\"multiple\",\n",
    "                                file_types=[\"text\", \"image\", \"audio\", \"video\", \".pdf\", \".json\", \".py\", \".js\", \".html\", \".css\", \".md\", \".docx\", \".doc\"],\n",
    "                                container=False,\n",
    "                                show_label=False,\n",
    "                                elem_classes=[\"compact-file-upload\"]\n",
    "                            )\n",
    "                    \n",
    "                    # Message input\n",
    "                    with gr.Column(scale=4):\n",
    "                        msg_box = gr.Textbox(\n",
    "                            placeholder=\"Speak to Falkor...\", \n",
    "                            show_label=False, \n",
    "                            container=False,\n",
    "                            lines=2\n",
    "                        )\n",
    "                    \n",
    "                    # Send button\n",
    "                    with gr.Column(scale=1, min_width=80):\n",
    "                        send_btn = gr.Button(\"Send\", variant=\"primary\", size=\"lg\")\n",
    "\n",
    "        # Add JavaScript for file upload visual feedback\n",
    "        gr.HTML(\"\"\"\n",
    "        <script>\n",
    "        function setupFileUploadIndicator() {\n",
    "            // Find the file input and indicator\n",
    "            const fileInputs = document.querySelectorAll('.compact-file-upload input[type=\"file\"]');\n",
    "            const indicator = document.getElementById('file-count-indicator');\n",
    "            \n",
    "            fileInputs.forEach(function(fileInput) {\n",
    "                if (!fileInput.hasChangeListener) {\n",
    "                    fileInput.hasChangeListener = true;\n",
    "                    fileInput.addEventListener('change', function() {\n",
    "                        const fileCount = this.files.length;\n",
    "                        const button = document.querySelector('.file-upload-button');\n",
    "                        \n",
    "                        if (fileCount > 0) {\n",
    "                            if (indicator) {\n",
    "                                indicator.textContent = fileCount;\n",
    "                                indicator.style.display = 'flex';\n",
    "                            }\n",
    "                            if (button) {\n",
    "                                button.style.borderColor = '#d4af37';\n",
    "                                button.style.backgroundColor = '#4b5563';\n",
    "                            }\n",
    "                        } else {\n",
    "                            if (indicator) {\n",
    "                                indicator.style.display = 'none';\n",
    "                            }\n",
    "                            if (button) {\n",
    "                                button.style.borderColor = '#4b5563';\n",
    "                                button.style.backgroundColor = '#374151';\n",
    "                            }\n",
    "                        }\n",
    "                    });\n",
    "                }\n",
    "            });\n",
    "        }\n",
    "        \n",
    "        // Setup when the page loads and after content changes\n",
    "        document.addEventListener('DOMContentLoaded', setupFileUploadIndicator);\n",
    "        setTimeout(setupFileUploadIndicator, 1000);\n",
    "        setInterval(setupFileUploadIndicator, 3000); // Periodic check\n",
    "        </script>\n",
    "        \"\"\")\n",
    "\n",
    "        # Hidden states to track rooms and conversations\n",
    "        current_room_state = gr.State(\"\")\n",
    "        global_chat_history = gr.State([])  # Stores ALL conversations across rooms for Claude's memory\n",
    "        room_chat_displays = gr.State({     # Stores room-specific chat displays\n",
    "            \"Shadow Dungeon\": [],\n",
    "            \"Dream Chamber\": [],\n",
    "            \"Alchemist's Workshop\": [],\n",
    "            \"Mandala Garden\": [],\n",
    "            \"Castle Gates\": []\n",
    "        })\n",
    "\n",
    "    # Room selection function - now manages room-specific displays\n",
    "    room_display = {\n",
    "        \"Shadow Dungeon\": \"You are entering the Shadow Dungeon. Prepare to face repressed aspects of the self...\",\n",
    "        \"Dream Chamber\": \"You sit in the Dream Chamber. Dreams rise like mist from the unconscious.\",\n",
    "        \"Alchemist's Workshop\": \"You discover the Alchemist's Workshop. Prepare your transformative vessel.\",\n",
    "        \"Mandala Garden\": \"You step into the Mandala Garden. Let unconscious content take symbolic form.\",\n",
    "        \"Castle Gates\": \"Welcome to the castle gates. Prepare yourself for the quests which lie beyond.\"\n",
    "    }   \n",
    "\n",
    "    def select_room(room_name, room_displays):\n",
    "        room_intro = room_display.get(room_name, \"\")\n",
    "        # Get the chat history for this specific room\n",
    "        room_chat_history = room_displays.get(room_name, [])\n",
    "        \n",
    "        return (\n",
    "            gr.update(value=f\"{room_intro}\", visible=True),\n",
    "            gr.update(value=room_chat_history, visible=True),  # Show room-specific chat\n",
    "            gr.update(visible=True),\n",
    "            room_name,\n",
    "            room_displays\n",
    "        )\n",
    "\n",
    "    # Connect room selection buttons\n",
    "    shadow_btn.click(\n",
    "        fn=lambda room_displays: select_room(\"Shadow Dungeon\", room_displays),\n",
    "        inputs=[room_chat_displays],\n",
    "        outputs=[current_room_display, chatbot, chat_row, current_room_state, room_chat_displays]\n",
    "    )\n",
    "    \n",
    "    dream_btn.click(\n",
    "        fn=lambda room_displays: select_room(\"Dream Chamber\", room_displays),\n",
    "        inputs=[room_chat_displays],\n",
    "        outputs=[current_room_display, chatbot, chat_row, current_room_state, room_chat_displays]\n",
    "    )\n",
    "    \n",
    "    imagination_btn.click(\n",
    "        fn=lambda room_displays: select_room(\"Alchemist's Workshop\", room_displays),\n",
    "        inputs=[room_chat_displays],\n",
    "        outputs=[current_room_display, chatbot, chat_row, current_room_state, room_chat_displays]\n",
    "    )\n",
    "    \n",
    "    mandala_btn.click(\n",
    "        fn=lambda room_displays: select_room(\"Mandala Garden\", room_displays),\n",
    "        inputs=[room_chat_displays],\n",
    "        outputs=[current_room_display, chatbot, chat_row, current_room_state, room_chat_displays]\n",
    "    )\n",
    "    \n",
    "    integration_btn.click(\n",
    "        fn=lambda room_displays: select_room(\"Castle Gates\", room_displays),\n",
    "        inputs=[room_chat_displays],\n",
    "        outputs=[current_room_display, chatbot, chat_row, current_room_state, room_chat_displays]\n",
    "    )\n",
    "\n",
    "    # Connect chat interactions with file support\n",
    "    msg_box.submit(\n",
    "        fn=user_interaction,\n",
    "        inputs=[msg_box, global_chat_history, current_room_state, room_chat_displays, file_upload],\n",
    "        outputs=[chatbot, global_chat_history, room_chat_displays, msg_box, file_upload]\n",
    "    )\n",
    "    \n",
    "    send_btn.click(\n",
    "        fn=user_interaction,\n",
    "        inputs=[msg_box, global_chat_history, current_room_state, room_chat_displays, file_upload],\n",
    "        outputs=[chatbot, global_chat_history, room_chat_displays, msg_box, file_upload]\n",
    "    )\n",
    "\n",
    "    # Button action to switch views + play audio + show Falkor modal\n",
    "    def go_to_main():\n",
    "        return (\n",
    "            gr.update(visible=False), \n",
    "            gr.update(visible=True), \n",
    "            gr.update(visible=True),\n",
    "            gr.HTML(\"\"\"\n",
    "            <div id=\"falkor-modal\" style=\"display: block; position: fixed; z-index: 1000; left: 0; top: 0; width: 100%; height: 100%; background-color: rgba(0,0,0,0.8);\">\n",
    "                <div style=\"background-color: #1a1a1a; margin: 10% auto; padding: 30px; border: 2px solid #444; border-radius: 15px; width: 80%; max-width: 500px; text-align: center; color: #ffffff; font-family: 'Merriweather', serif;\">\n",
    "                    <h2 style=\"color: #d4af37; margin-bottom: 20px;\">üêâ Meet Falkor</h2>\n",
    "                    <p style=\"font-size: 16px; line-height: 1.6; margin-bottom: 20px;\">\n",
    "                        Greetings, fellow traveler. I am Falkor, your guide through the depths of the psyche. Together, we shall explore the symbolic realm of your unconscious, confront shadows, interpret dreams, and walk the path towards individuation.\n",
    "                    </p>\n",
    "                    <p style=\"font-style: italic; margin-bottom: 25px; color: #ccc;\">\n",
    "                        \"Who looks outside, dreams; who looks inside, awakens.\" - C.G. Jung\n",
    "                    </p>\n",
    "                    <button onclick=\"this.parentElement.parentElement.style.display='none'\" \n",
    "                            style=\"background-color: #d4af37; color: #000; border: none; padding: 10px 20px; border-radius: 5px; cursor: pointer; font-size: 16px; font-weight: bold;\">\n",
    "                        Begin the Journey\n",
    "                    </button>\n",
    "                </div>\n",
    "            </div>\n",
    "            \"\"\")\n",
    "        )\n",
    "\n",
    "    proceed_btn.click(fn=go_to_main, inputs=[], outputs=[welcome_page, main_page, audio, falkor_modal])\n",
    "\n",
    "# Run the app\n",
    "if __name__ == \"__main__\": \n",
    "    demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
